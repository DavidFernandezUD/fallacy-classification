{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7a3564",
   "metadata": {},
   "source": [
    "# Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74f51bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa04894",
   "metadata": {},
   "source": [
    "# Descargar datasets y combinarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06e89feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['config', 'source_article', 'logical_fallacies'],\n",
      "        num_rows: 2901\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['config', 'source_article', 'logical_fallacies'],\n",
      "        num_rows: 598\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['config', 'source_article', 'logical_fallacies'],\n",
      "        num_rows: 539\n",
      "    })\n",
      "})\n",
      "Train examples: 2901\n",
      "Dev examples:   598\n",
      "Test examples:  539\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Diccionario para mapear tipos de falacia del segundo dataset a las clases del primero\n",
    "fallacy_mapping = {\n",
    "    # ad hominem\n",
    "    \"Ad Hominem\": \"ad hominem\",\n",
    "    \"Circumstantial Ad Hominem\": \"ad hominem\",\n",
    "    \"Tu Quoque\": \"ad hominem\",\n",
    "    \"Abusive Ad Hominem\": \"ad hominem\",\n",
    "    \"Guilt By Association\": \"ad hominem\",\n",
    "    \"Argument From Commitment\": \"ad hominem\",\n",
    "    \"Precedent Ad Hominem\": \"ad hominem\",\n",
    "    \"Behavioral Ad Hominem\": \"ad hominem\",\n",
    "    \"Ad Hominem Against a Witness at Trial\": \"ad hominem\",\n",
    "\n",
    "    # false dilemma\n",
    "    \"False Dichotomy\": \"false dilemma\",\n",
    "    \"False Dilemma/Dichotomy\": \"false dilemma\",\n",
    "    \"False dilemma\": \"false dilemma\",\n",
    "\n",
    "    # ad populum\n",
    "    \"Appeal to Popularity\": \"ad populum\",\n",
    "    \"Bandwagon Fallacy\": \"ad populum\",\n",
    "    \"Common Belief Fallacy\": \"ad populum\",\n",
    "\n",
    "    # equivocation\n",
    "    \"Equivocation\": \"equivocation\",\n",
    "\n",
    "    # fallacy of credibility\n",
    "    \"Argument from Authority\": \"fallacy of credibility\",\n",
    "    \"Appeal to Authority\": \"fallacy of credibility\",\n",
    "    \"Appeal to False Authority\": \"fallacy of credibility\",\n",
    "    \"Argument from False Authority\": \"fallacy of credibility\",\n",
    "    \"Appealing to an irrelevant authority\": \"fallacy of credibility\",\n",
    "\n",
    "    # false causality\n",
    "    \"Correlation does not imply causation\": \"false causality\",\n",
    "    \"False cause\": \"false causality\",\n",
    "    \"Post hoc ergo propter hoc\": \"false causality\",\n",
    "    \"Cum hoc ergo propter hoc\": \"false causality\",\n",
    "\n",
    "    # intentional\n",
    "    \"Intentional Fallacy\": \"intentional\",\n",
    "    \"Authorial Intent as Constraint\": \"intentional\",\n",
    "\n",
    "    # fallacy of logic / circular reasoning\n",
    "    \"Circular Reasoning\": \"circular reasoning\",\n",
    "    \"Circular reasoning\": \"circular reasoning\",\n",
    "    \"Fallacy of Logic\": \"fallacy of logic\",\n",
    "    \"Begging the question\": \"fallacy of logic\",\n",
    "    \"Begging the Question\": \"fallacy of logic\",\n",
    "\n",
    "    # appeal to emotion\n",
    "    \"Appeal to Emotion\": \"appeal to emotion\",\n",
    "    \"Appeal to emotion\": \"appeal to emotion\",\n",
    "    \"Appeal to Pity\": \"appeal to emotion\",\n",
    "    \"Appeal to fear\": \"appeal to emotion\",\n",
    "    \"Appeal to consequences\": \"appeal to emotion\",\n",
    "\n",
    "    # fallacy of relevance / extension\n",
    "    \"Fallacy of Extension\": \"fallacy of extension\",\n",
    "    \"Fallacy of Relevance\": \"fallacy of relevance\",\n",
    "    \"Red Herring\": \"fallacy of relevance\",\n",
    "    \"Straw Man\": \"fallacy of relevance\",\n",
    "    \"Straw man\": \"fallacy of relevance\",\n",
    "    \"Strawman\": \"fallacy of relevance\",\n",
    "\n",
    "    # faulty generalization\n",
    "    \"Hasty Generalization\": \"faulty generalization\",\n",
    "    \"Faulty Generalization \": \"faulty generalization\",\n",
    "    \"Hasty generalization\": \"faulty generalization\",\n",
    "    \"Accident\": \"faulty generalization\",\n",
    "    \"Generalization\": \"faulty generalization\",\n",
    "}\n",
    "\n",
    "# Cargar datasets\n",
    "dataset1 = load_dataset(\"tasksource/logical-fallacy\")\n",
    "dataset2 = load_dataset(\"MrOvkill/fallacies-fallacy-base\")\n",
    "\n",
    "train1, test1, dev1 = dataset1[\"train\"], dataset1[\"test\"], dataset1[\"dev\"]\n",
    "\n",
    "# Mapear clases del dataset2 a las del dataset1\n",
    "def map_fallacy(example):\n",
    "    mapped = fallacy_mapping.get(example[\"name\"])\n",
    "    return {\"logical_fallacies\": mapped}\n",
    "\n",
    "dataset2_mapped = dataset2[\"train\"].map(map_fallacy)\n",
    "dataset2_mapped = dataset2_mapped.filter(lambda x: x[\"logical_fallacies\"] is not None)\n",
    "\n",
    "# Mantener solo columnas necesarias\n",
    "dataset2_mapped = dataset2_mapped.remove_columns(\n",
    "    [c for c in dataset2_mapped.column_names if c not in [\"logical_fallacies\", \"example\"]]\n",
    ")\n",
    "\n",
    "# Dividir dataset2 en train/dev/test (80/10/10)\n",
    "data_array = dataset2_mapped[\"example\"]\n",
    "labels_array = dataset2_mapped[\"logical_fallacies\"]\n",
    "\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    data_array, labels_array, test_size=0.2, stratify=labels_array, random_state=42\n",
    ")\n",
    "dev_texts, test_texts, dev_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "train2 = Dataset.from_dict({\"example\": train_texts, \"logical_fallacies\": train_labels})\n",
    "dev2   = Dataset.from_dict({\"example\": dev_texts, \"logical_fallacies\": dev_labels})\n",
    "test2  = Dataset.from_dict({\"example\": test_texts, \"logical_fallacies\": test_labels})\n",
    "\n",
    "train2 = train2.rename_column(\"example\", \"source_article\")\n",
    "dev2   = dev2.rename_column(\"example\", \"source_article\")\n",
    "test2  = test2.rename_column(\"example\", \"source_article\")\n",
    "\n",
    "# Combinar datasets\n",
    "train_combined = concatenate_datasets([train1, train2])\n",
    "dev_combined   = concatenate_datasets([dev1, dev2])\n",
    "test_combined  = concatenate_datasets([test1, test2])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_combined,\n",
    "    \"dev\": dev_combined,\n",
    "    \"test\": test_combined\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "print(f\"Train examples: {len(dataset['train'])}\")\n",
    "print(f\"Dev examples:   {len(dataset['dev'])}\")\n",
    "print(f\"Test examples:  {len(dataset['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d7fc99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Descargar modelos de tonekizacion\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b41cc",
   "metadata": {},
   "source": [
    "# Tokenizacion + case-folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ebe3bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2680/2680 [00:00<00:00, 6853.85 examples/s]\n",
      "Map: 100%|██████████| 511/511 [00:00<00:00, 7522.64 examples/s]\n",
      "Map: 100%|██████████| 570/570 [00:00<00:00, 7298.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigger a child's shoe size, the better the child's handwriting\n",
      "['the', 'bigger', 'a', 'child', \"'s\", 'shoe', 'size', ',', 'the', 'better', 'the', 'child', \"'s\", 'handwriting']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize_flat(text):\n",
    "    text = text.lower()\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        tokens.extend(word_tokenize(sentence))\n",
    "    return tokens\n",
    "\n",
    "# NOTE: Esta funcion tokeniza cada frase por separado. Podria ser interesante.\n",
    "def preprocess_sentences(text):\n",
    "    text = text.lower()\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return tokenized_sentences\n",
    "\n",
    "train = train.map(lambda x: {\"tokenized\": tokenize_flat(x[\"source_article\"])})\n",
    "test  = test.map(lambda x: {\"tokenized\": tokenize_flat(x[\"source_article\"])})\n",
    "dev   = dev.map(lambda x: {\"tokenized\": tokenize_flat(x[\"source_article\"])})\n",
    "\n",
    "print(train[1][\"source_article\"])\n",
    "print(train[1][\"tokenized\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508aa0f",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33bdef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Bag-of-Words ====\n",
      "Dimensiones de la matriz BoW: (2680, 7952)\n",
      "Ejemplo de vocabulario:       ['borges', 'boring', 'boris', 'born', 'borrow', 'borrowed', 'borrowing', 'boss', 'both', 'bother', 'bottle', 'bottled', 'bottles', 'bottom', 'bought', 'bouncing']\n",
      "\n",
      "Similitud coseno entre primeros documentos (BoW):\n",
      "[[1.    0.    0.    0.    0.   ]\n",
      " [0.    1.    0.    0.    0.221]\n",
      " [0.    0.    1.    0.053 0.   ]\n",
      " [0.    0.    0.053 1.    0.26 ]\n",
      " [0.    0.221 0.    0.26  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_corpus = [\" \".join(tokens) for tokens in train[\"tokenized\"]]\n",
    "\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_matrix = bow_vectorizer.fit_transform(train_corpus)\n",
    "\n",
    "print(\"==== Bag-of-Words ====\")\n",
    "print(f\"Dimensiones de la matriz BoW: {bow_matrix.shape}\")\n",
    "print(f\"Ejemplo de vocabulario:       {list(bow_vectorizer.get_feature_names_out()[1000:1016])}\")\n",
    "\n",
    "# Calculamos similitud entre algunos documentos\n",
    "similarity_bow = cosine_similarity(bow_matrix[:5])\n",
    "print(\"\\nSimilitud coseno entre primeros documentos (BoW):\")\n",
    "print(np.round(similarity_bow, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac40ef",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4459fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== TF-IDF ====\n",
      "Dimensiones de la matriz TF-IDF: (2680, 7952)\n",
      "Ejemplo de vocabulario:          ['borges', 'boring', 'boris', 'born', 'borrow', 'borrowed', 'borrowing', 'boss', 'both', 'bother', 'bottle', 'bottled', 'bottles', 'bottom', 'bought', 'bouncing']\n",
      "\n",
      "Similitud coseno entre primeros documentos (TF-IDF):\n",
      "[[1.    0.    0.    0.    0.   ]\n",
      " [0.    1.    0.    0.    0.021]\n",
      " [0.    0.    1.    0.033 0.   ]\n",
      " [0.    0.    0.033 1.    0.167]\n",
      " [0.    0.021 0.    0.167 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_corpus)\n",
    "\n",
    "print(\"\\n==== TF-IDF ====\")\n",
    "print(f\"Dimensiones de la matriz TF-IDF: {tfidf_matrix.shape}\")\n",
    "print(f\"Ejemplo de vocabulario:          {list(tfidf_vectorizer.get_feature_names_out()[1000:1016])}\")\n",
    "\n",
    "# Similitud coseno entre los algunos documentos\n",
    "similarity_tfidf = cosine_similarity(tfidf_matrix[:5])\n",
    "print(\"\\nSimilitud coseno entre primeros documentos (TF-IDF):\")\n",
    "print(np.round(similarity_tfidf, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4fa99209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Documento 0 - Palabras más relevantes (TF-IDF):\n",
      "slogan: 0.5407\n",
      "expect: 0.4204\n",
      "pay: 0.4204\n",
      "company: 0.3994\n",
      "less: 0.3577\n",
      "more: 0.2583\n",
      "existed: 0.0000\n",
      "existence: 0.0000\n",
      "existential: 0.0000\n",
      "exist: 0.0000\n",
      "\n",
      "Documento 1 - Palabras más relevantes (TF-IDF):\n",
      "child: 0.5770\n",
      "handwriting: 0.4045\n",
      "bigger: 0.3845\n",
      "shoe: 0.3593\n",
      "size: 0.3427\n",
      "better: 0.2457\n",
      "the: 0.2210\n",
      "exhausted: 0.0000\n",
      "exhibit: 0.0000\n",
      "exist: 0.0000\n",
      "\n",
      "Documento 2 - Palabras más relevantes (TF-IDF):\n",
      "true: 0.4081\n",
      "many: 0.3721\n",
      "since: 0.3642\n",
      "believe: 0.3527\n",
      "then: 0.3412\n",
      "must: 0.3048\n",
      "people: 0.2821\n",
      "this: 0.2425\n",
      "be: 0.2186\n",
      "it: 0.2060\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Palabras mas relevantes por documento\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_top_words(tfidf_vector, feature_names, top_n=10):\n",
    "    sorted_nzs = np.argsort(tfidf_vector)[-top_n:][::-1]\n",
    "    return [(feature_names[i], tfidf_vector[i]) for i in sorted_nzs]\n",
    "\n",
    "for idx in range(3):\n",
    "    print(f\"\\nDocumento {idx} - Palabras más relevantes (TF-IDF):\")\n",
    "    top_words = get_top_words(tfidf_array[idx], feature_names)\n",
    "    for word, score in top_words:\n",
    "        print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16350008",
   "metadata": {},
   "source": [
    "# Embedding no contextual con Word2Vec (fine-tuneado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3613db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario del dataset: 9977 palabras.\n",
      "Embeddings inicializados desde el modelo base: 8084/9977\n",
      "Loss after epoch 0: 0.0\n",
      "Loss after epoch 1: 0.0\n",
      "Loss after epoch 2: 0.0\n",
      "Loss after epoch 3: 0.0\n",
      "Loss after epoch 4: 0.0\n",
      "Loss after epoch 5: 0.0\n",
      "Loss after epoch 6: 0.0\n",
      "Loss after epoch 7: 0.0\n",
      "Loss after epoch 8: 0.0\n",
      "Loss after epoch 9: 0.0\n",
      "Modelo fine-tuneado guardado correctamente.\n",
      "Cobertura antes del fine-tuning: 75.84%\n",
      "Cobertura después del fine-tuning: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n",
    "\n",
    "# Cargar modelo base preentrenado de Word2Vec\n",
    "base_model = KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=400000)\n",
    "\n",
    "train_tokens = list(train[\"tokenized\"])\n",
    "test_tokens  = list(test[\"tokenized\"])\n",
    "dev_tokens   = list(dev[\"tokenized\"])\n",
    "all_sentences = train_tokens + test_tokens + dev_tokens\n",
    "\n",
    "epoch_logger = EpochLogger()\n",
    "\n",
    "# Crear un nuevo modelo Word2Vec para fine-tuning\n",
    "model = Word2Vec(\n",
    "    vector_size=base_model.vector_size,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    sg=1,\n",
    "    negative=5,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "# Construir vocabulario a partir de nuestro dataset\n",
    "model.build_vocab(all_sentences)\n",
    "print(f\"Vocabulario del dataset: {len(model.wv)} palabras.\")\n",
    "\n",
    "# Inicializar embeddings desde el modelo preentrenado\n",
    "overlap = 0\n",
    "for word in model.wv.key_to_index:\n",
    "    if word in base_model.key_to_index:\n",
    "        model.wv[word] = base_model[word]\n",
    "        overlap += 1\n",
    "print(f\"Embeddings inicializados desde el modelo base: {overlap}/{len(model.wv)}\")\n",
    "\n",
    "# Fine-tuning con nuestro dataset\n",
    "model.train(\n",
    "    all_sentences,\n",
    "    total_examples=len(all_sentences),\n",
    "    epochs=10,\n",
    "    callbacks=[epoch_logger]\n",
    ")\n",
    "\n",
    "# Guardar el modelo fine-tuneado\n",
    "model.save(\"./models/word2vec_finetuned_fallacies.model\")\n",
    "print(\"Modelo fine-tuneado guardado correctamente.\")\n",
    "\n",
    "def compute_coverage(dataset, model):\n",
    "\n",
    "    total = 0\n",
    "    covered = 0\n",
    "\n",
    "    # Si es KeyedVectors, usamos model.key_to_index\n",
    "    vocab = model.key_to_index if isinstance(model, KeyedVectors) else model.wv.key_to_index\n",
    "\n",
    "    for tokens in dataset:\n",
    "        for t in tokens:\n",
    "            total += 1\n",
    "            if t in vocab:\n",
    "                covered += 1\n",
    "    return covered / total if total > 0 else 0\n",
    "\n",
    "cov_before = compute_coverage(train_tokens, base_model)\n",
    "cov_after  = compute_coverage(train_tokens, model)\n",
    "print(f\"Cobertura antes del fine-tuning: {cov_before:.2%}\")\n",
    "print(f\"Cobertura después del fine-tuning: {cov_after:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f56cf",
   "metadata": {},
   "source": [
    "# Embedding contextual con BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5ae1bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo: embedding promedio train[0] shape: torch.Size([768])\n",
      "Similitud coseno entre train[0] y train[1]: 0.5843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar modelo y tokenizer BERT preentrenado\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "def get_bert_avg_embeddings(sentences, batch_size=16, max_length=128, device='cpu'):\n",
    "\n",
    "    model.to(device)\n",
    "    avg_embeddings = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        batch_texts = [\" \".join(s) for s in batch]\n",
    "        encoded = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors='pt',\n",
    "            padding=True, # Paddear cada batch al tamaño del batch más largo\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "            for j in range(len(batch)):\n",
    "                # Promediar solo sobre tokens reales (ignorar padding)\n",
    "                attention_mask = encoded['attention_mask'][j].unsqueeze(-1)\n",
    "                sum_emb = (outputs.last_hidden_state[j] * attention_mask).sum(dim=0)\n",
    "                length = attention_mask.sum()\n",
    "                avg_embeddings.append(sum_emb / length)\n",
    "\n",
    "    return avg_embeddings\n",
    "\n",
    "# Generar embeddings para train/test/dev\n",
    "train_sentences = list(train[\"tokenized\"])\n",
    "test_sentences  = list(test[\"tokenized\"])\n",
    "dev_sentences   = list(dev[\"tokenized\"])\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_embeddings = get_bert_avg_embeddings(train_sentences, device=device)\n",
    "test_embeddings  = get_bert_avg_embeddings(test_sentences, device=device)\n",
    "dev_embeddings   = get_bert_avg_embeddings(dev_sentences, device=device)\n",
    "\n",
    "print(f\"Ejemplo: embedding promedio train[0] shape: {train_embeddings[0].shape}\")  # 768-d\n",
    "\n",
    "# Ejemplo de similitud coseno\n",
    "sim = F.cosine_similarity(train_embeddings[0], train_embeddings[1], dim=0)\n",
    "print(f\"Similitud coseno entre train[0] y train[1]: {sim.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
